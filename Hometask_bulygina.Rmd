---
title: "Домашнее задание (ht_a)"
author: "Арина Булыгина"
output:
    pdf_document:
        keep_tex: yes
header-includes:
   - \usepackage[T2A]{fontenc}
   - \usepackage[utf8]{inputenc}
   - \usepackage[russian]{babel}
---

Подключаем необходимые пакеты

```{r include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(car)
library(lmtest)
library(dynlm)
library(sandwich)
library(tidyr)
library(dplyr)
library(ggplot2)
library(purrr)
library(tidyr)
library(pastecs)
library(stargazer) #fancy regression tables
library(glmnet) #LASSO
library(fastDummies)
library(boot) #Для ленивого bootstrap
```

№0. Загружаем данные и устанавливаем seed для воспроизводимости.
```{r}
data <- read.csv('https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv', header = TRUE)
set.seed(14)
```
№1
Убираем нулевые значения area. Интересно, что она, как видно из гистограммы, имеет распределение похожее на логнормальное с сильно растянутым хвостом, отвечающим за крупные пожары. Логарифмирование превращает распределение в нормальное: Шапиро-Уилк показывает p-value в 0.24, значит на любом вменяемом уровне значимости мы не отвергаем гипотезу о нормальности. Но по заданию используем просто area.
На случай, если пригодится, month и day преобразовываем в факторы.

```{r echo=TRUE, warning=FALSE}
data <- data[which(data$area != 0), ]
hist(data$area[which(data$area<200)],breaks=50,xlab = "area in ha", main = paste("Histogram of" , "burned area distribution"))
data$month <- as.factor(data$month)
data$day <- as.factor(data$day)
hist(log(data$area), breaks=20, xlab = "log(area)", main = paste("Histogram of" , "logarithmic burned area distribution"))
shapiro.test(log(data$area))
```
№2 
Отбираем признаки для модели из содержательных соображений. 

Базовые переменные для погодных условий:

temp,RH,wind,rain  - выбираем, так как в напрямую показываюют погодные условия.
Ожидаемые знаки коэффициентов при переменных:

rain <0: ожидаем отрицательную зависимость, так как чем меньше дождя в какой-либо области, тем более высокой будет площадь пожара. Проблема с этой переменной в том, что у неё всего 2 ненулевых значения, а значит она бесполезна и далее в регрессиях она встречаться не будет.

wind >0 : чем выше скорость ветра, тем быстрее и дальше разносится пожар в какой-либо области, значит, площадь пожара будет выше. С другой стороны, сильный ветер в условиях средней влажности может наоборот гасить небольшие источники пламени, что уменьшает потенциальный ущерб, однако эта логика больше применима к общему случаю, когда мы не исключаем 0 в area.

temp >0: чем выше температура, тем больше вероятность возгорания травы и сухостоя, тем больше потенциальных очагов и, следовательно, площадь пожара растёт.

RH <0: больше влажность - больше паров воды в воздухе, значит отсыревает потенциально горючий мусор и ветки, значит меньше вероятность пожара. Понятно, что важна относительность влажности, чтобы говорить о количестве воды, но мы здесь в основно говорим про лето и высокую температуру, так что насыщенность примерно сопоставима, но возможно учёт совместно двух этих параметров в виде произведения даст больше предсказывающей мощности.

Индексы, которые можно дополнительно включить:

FFMC, DMC, ISI, DC - различные комбинации факторов выше, которые тоже в целом говорят о вероятности возгорания и возможной скорости распространения пожара. Тут проблема может возникнуть со смещением из-за ошибок измерения и, вероятно, с мультиколлинеарностью, так как факторы связаны.
Ожидаемые знаки коэффициентов:

DMC, DC, FFMC >0 : по методологии FWI, общая идея индексов - растут, когда вероятность пожара или его распространения увеличивается. DMC - про влажность возгораемых веществ в толще земли, растёт с понижением влажности (он самый важный из указанных для нас, так как отвечает именно за распространение, а не возникновение, потому что подсчитывает засуху именно в средних слоях почвы, которые загораются не первыми). DC - про засуху глубинных слоёв (увеличивается с ней), FFMC - про вероятность возгорания(тоже через влажность) (Примечание: индексы имеют лаг измерения, т.е. сегодняшний индекс на самом деле построен по какому-то измерению n дней назад с оценкой испарения. Это сознательный выбор методологов из-за разной волатильности влажности в разных слоях почвы: замерять в глубине можно менее часто, чем на поверхности. Наличие такого лага возможно сильно зашумляет данные по индексам, так что многого ждать не стоит.)

ISI >0: это главная оценка скорости распространения(тоже значимый). Он агрегирует в себе предыдущие индексы, а также отдельно ветер, поэтому с ним вероятнее всего будет сильная мультиколлинеарность, хотя зависимости не линейные, так что посмотрим ниже.

Переменные для контроля:

day: скорее всего по выходным будет бОльшая вероятность пожара из-за повышения числа людей, приехавших отдохнуть. Мусорят, не следят за кострами - вот и боль. Как контрольные факторы можно включить.

month: судя по данным в августе и сентябре больше всего пожаров. Это логично, потому что сезоны засухи и пожаров как раз летом. Логично предположить, что в это время чисто статистически площадь будет больше, но мы тут исследуем влияние именно погодных условий, так что сгодится разве что на контроль.

Описательная статистика по интересующим переменным в коде ниже:
```{r}
data <- data[,-c(1,2)]
res <- stat.desc(data[, -c(1:2)])
round(res, 2)
```

Смотрим на гистограммы распределения и сглаженные плотности.

Как можно увидеть, у многих переменных распределение похоже на нормальное или близкое к нему. Реально же гипотеза о нормальности распределения в тесте Шапиро-Уилка отвергается для всех переменных. Это в общем-то логично, так как мы сильно урезали данные до экстремальных случаев, когда происходило возгарание, то есть убрали потенциально важные для "нормальности" диапазоны значений объясняющих переменных.

Значимые замечания:

FFMC в силу специфики расчёта, как говорит сайт канадской системы FWI, обычно колеблется в слабом диапазоне в периоды пожаров, и лишь сигнализирует, когда сильные дожди пропитывают землю (он в этих случаях снижает значение), отсюда и такое остроконечное распределение с редкими низкими значениями. 

Смещение RH в сторону низких значений обусловлено тем, что у нас здесь данные по случившимся пожарам, а исходя из логики,описанной выше, они как раз случаются при влажности низкой, при прочих равных.

Содержательно инетерсно, что значения температуры сильно разбросаны (2-33). Скорее всего это связано с наличием антропогенного фактора: даже в холодную погоду были пожары, потому что люди жгли костры. Реально для подтверждения этой гипотезы данных нет, но возгорания зимой (dec, feb) случались даже чаще, чем в весенние месяцы. Коли речь о месяцах, упомяну, что, как и отмечалось, большая часть пожаров происходит в районе августа, сентября (примерно 2/3 всех). Возможно стоит отдельно рассмотреть пожары за эти периоды.

Интересны и данные по дням недели. В целом видно, что в выходные и их окрестности, в частности, в воскресенье, число пожаров больше, и, учитывая, что погода не зависит от дня недели, уже можно говорить о том, что некоторое влияние выходные всё же оказывают, так что в модель всё же стоит включить.

```{r}
#Гистограммы
g <- data %>%
  keep(is.numeric) %>%                     
  gather() %>%                             
  ggplot(aes(value)) +                     
    facet_wrap(~ key, scales = "free") +   
    geom_histogram() 
g <- g+labs(title = "Distribution histograms", x="Variable value", y="Number of fires occured")
g

#Плотности
g1 <- data %>%
  keep(is.numeric) %>%                     
  gather() %>%                             
  ggplot(aes(value)) +            
    facet_wrap(~ key, scales = "free") +   
    geom_density()
    
g1 <- g1+labs(title = "Distribution density", x="Variable value", y="Number of fires occured")
g1

#Тест на нормальность
lapply(data[,-c(1,2)], shapiro.test)

#Пожары по месяцам
ggplot(data, aes(x = month)) + 
  geom_bar() +
  labs(title = "Distribution of fires by month",y="Number of fires occured", x = "Month")


#Пожары по дням
ggplot(data, aes(x = day)) + 
  geom_bar() +
  labs(title = "Distribution of fires by week day",y="Number of fires occured", x = "Week day")


#дополнительные графики для прикидки взаимосвязей
#qplot(data=data, temp, area)
#qplot(data=data, day, area)
#qplot(data=data, month, area)
#qplot(data=data, RH, area)
```

Далее смотрим на коробчатые диаграммы, чтобы оценить выбросы и избавиться от них. Самые значительные выбросы у нас наблюдаются по площади пожаров(area), числу осадков(rain) и по значениям индексов,которые будучи агрегированными, тяжело интерпретируются в терминах выбросов, так что на основе их анализа ничего не удаляем.

Если посчитать, то у нас 2 наблюдения с экстремальными по площади пожарами (>600га выжженной земли). Подобные выбросы (при медиане в 6га) сильно исказят наши результаты в случае использования МНК, потому удаляем их. В случае с площадью можно ещё сильнее порезать выборку, например, по границе в 90га (тогда будет удалено ещё 10 наблюдений), однако это будут уже не такие серьёзные выбросы, так что это решение будет принято по ходу подгонки моделей.

По rain для большей однородности данных тоже убераем 2 наблюдения, где rain!=0.
```{r}
#boxplot
g <- data %>%
  keep(is.numeric) %>%                     
  gather() %>%                            
  ggplot(aes(x="",y=value)) +                     
    facet_wrap(~ key, scales = "free") +   
    geom_boxplot() 
g <- g+labs(title = "Variable distribution box plot", x="", y="Variable value")
g

#Считаем выбросы и чистим от них выборку/
summary(data)
count(data[which(data$rain>0),])
count(data[which(data$area>90),])
data <- data[which(data$area<300& data$rain==0),]

```
№3
Для того, чтобы посмотреть на мультиколлинеарность, построим несколько версий линейных моделей и оценим для них VIF и CN. Спецификации пояснены в коде. Логика такого разбиения моделей продиктована порядком выбора переменных: от чистых к агрегированным и далее ещё дополнительный контроль.

Для начала сравниваются результаты по двум выборкам (data1, где выбросы area>90 отрезаны, и data, где выбросы>300 отрезаны), по итогу коэффициенты и значения статистик всё же достаточно сильно меняются, что может как раз говорить о мультиколлинеарности. Но R^2 больше у модели на выборке с большим числом наблюдений(data), поэтому её и оставим. 

Для проверки на мультиколлинеарность считаются VIF и CN по каждому набору переменных в модели. По итогу анализа выясняем, что даже в наборе из трёх переменных (RH, temp, wind) матрица уже имеет достаточно маленькие собственные значения (CN=251) и даже, учитывая, что VIF <10, уже можно сказать, что мультиколлинеарность есть. При добавлении индексов CN(16502) увеличивается до огромного значения, так как мы знаем, что индексы зависят от трёх исходных параметров. Ну и с добавлением контроля на дни и месяцы уже даже VIF сигнализируют, что мультиколлинеарность есть. 

Таким образом в любой спецификации мы можем говорить о наличии мультиколлинеарности, а значит надо модифицировать функцию потерь, применив модель LASSO, и разобраться по-ковбойски. Прогнав LASSO регрессии по всем 4 спецификациям, получаем интересную картину: в случае с моделью 1 (RH, temp, wind) и моделью 4 (все регрессоры) все коэффициенты 0, то есть просто константа лучше описывает площадь пожара. При спецификации же с днями недели и коэффициентами пожароопасности наконец возникают ненулевые коэффициенты, которые не отличаются знаками от того, что даёт lm. При анализе этих ненулевых коэффициентов и сравнении квадратов остатков делаем вывод, что добавление дней недели не сильно улучшает объясняющие свойства модели, да и содержательно это очень плохие proxi антропогенной причины пожара, так что в итоге отказываемся и от включения дней.

Итогом анализа становится вывод, что надо оценивать модель с переменными ISI, DMC, temp, RH. У этих переменных ненулевые коэффициенты. Вот и оказалось, что DMC и ISI нам всё же важны. Переменная ветра всё же сильно увеличивает мультиколлинеарность, видимо из-за зашумлённости и нелинейного воздействия (форму этого воздействия из логики сложно выявить, а если подгонять полиномами - не ясно, где остановиться), потому добавлять в финальную регрессию не будем, однако стоит заметить, что в тех регрессиях, что были сделаны для пробы, знак при переменной соответствовал ожиданиям(+), хотя в условиях незначимости коэффициента трактовка лишена смысла.


```{r}
set.seed(14)
#Сравниваем модели
data <- data[,-c(10)] #убираем бесполезный rain

#Базовая на всю природу
model1 <- lm(area~RH +temp+wind, data)
#Добавляем коэффцициенты распространения пожара
model2 <- lm(area~. -month -day, data)
#Дополнительно переменные дня недели и месяца
model3 <- lm(area~. -month, data)
model4 <- lm(area~.,data)
#Итог
stargazer(model1, model2, model3, model4, title="Сравнение объясняющей мощности", type="text", 
                                        column.labels=c("Модель 1", "Модель 2","Модель 3", "Модель 4"), 
                                        df=FALSE, digits=3)

data1 <- data[which((data$area)<90),]
#Базовая на всю природу
model11 <- lm(area~RH +temp+wind, data1)
#Добавляем коэффцициенты распространения пожара
model21 <- lm(area~. -month -day, data1)
#Дополнительно переменные дня недели и месяца
model31 <- lm(area~. -month, data1)
model41 <- lm(area~.,data1)
#Итог
stargazer(model1, model11, model2, model21, model3, model31, model4, model41, title="Сравнение объясняющей мощности", type="text", 
                                        column.labels=c("Модель 1", "Модель 1", "Модель 2","Модель 2","Модель 3", "Модель 3","Модель 4","Модель 4"), 
                                        df=FALSE, digits=3)

#Мультиколлинеарность

#Для модели 1.
vif(model1)
kappa(model1)

#Для модели 2.
vif(model2)
kappa(model2)

#Для модели 3.
vif(model3)
kappa(model3)

#Для модели 4.
vif(model4)
kappa(model4)

#LASSO подбираем.

#train.index <- createDataPartition(y = data$area, p = 0.75, list = FALSE)
#data.train <- data[train.index, ] 
#data.test <- data[-train.index, ]

#Для модели 1.
x1=as.matrix(data[,7:9]) # матрица регрессоров
lasso1 <- cv.glmnet(x = x1, y=data$area, type.measure = "mse",family = 'gaussian', alpha=1) #оцениваем кросс-валидацией лучшую лямбду
lambda1 <- lasso1$lambda.min #запоминаем её
coef1 <- lasso1$glmnet.fit$beta[,lasso1$glmnet.fit$lambda==lambda1] #записываем коэффициенты (без константы)
coef1
#Сравниваем точность предсказания lasso и соответствующей обычной модели
mean((data$area-predict(lasso1,s=lambda1,newx=x1))^2) #средний квадрат отклонений (lasso)
mean((model1$residuals)^2) #средний квадрат отклонений (простая lm)

#Для модели 2.
x2=as.matrix(data[,3:9]) # матрица регрессоров
lasso2 <- cv.glmnet(x = x2, y=data$area, type.measure = "mse",family = 'gaussian', alpha=1) #оцениваем кросс-валидацией лучшую лямбду
lambda2 <- lasso2$lambda.min #запоминаем её
coef2 <- lasso2$glmnet.fit$beta[,lasso2$glmnet.fit$lambda==lambda2] #записываем коэффициенты (без константы)
coef2
#Сравниваем точность предсказания lasso и соответствующей обычной модели
mean((data$area-predict(lasso2,s=lambda2,newx=x2))^2) #средний квадрат отклонений (lasso)
mean((model2$residuals)^2) #средний квадрат отклонений (простая lm)

#Для модели 3.
x3=as.matrix(dummy_cols(data[,2:9])[,-c(1,11)]) # матрица регрессоров (исключили одну бинарную дня, чтобы избежать линейной зависимости)
lasso3 <- cv.glmnet(x = x3, y=data$area, type.measure = "mse",family = 'gaussian', alpha=1) #оцениваем кросс-валидацией лучшую лямбду
lambda3 <- lasso3$lambda.min #запоминаем её
coef3 <- lasso3$glmnet.fit$beta[,lasso3$glmnet.fit$lambda==lambda3] #записываем коэффициенты (без константы)
coef3
#Сравниваем точность предсказания lasso и соответствующей обычной модели
mean((data$area-predict(lasso3,s=lambda3,newx=x3))^2) #средний квадрат отклонений (lasso)
mean((model3$residuals)^2) #средний квадрат отклонений (простая lm)

#Для модели 4.
x4=as.matrix(dummy_cols(data[,1:9])[,-c(1:2,9,23)]) # матрица регрессоров (исключили по одной бинарной переменной дня и месяца, чтобы избежать линейной зависимости)
lasso4 <- cv.glmnet(x = x4, y=data$area, type.measure = "mse",family = 'gaussian', alpha=1) #оцениваем кросс-валидацией лучшую лямбду
lambda4 <- lasso4$lambda.min #запоминаем её
coef4 <- lasso4$glmnet.fit$beta[,lasso4$glmnet.fit$lambda==lambda4] #записываем коэффициенты (без константы)
coef4
#Сравниваем точность предсказания lasso и соответствующей обычной модели
mean((data$area-predict(lasso4,s=lambda4,newx=x4))^2) #средний квадрат отклонений (lasso)
mean((model4$residuals)^2) #средний квадрат отклонений (простая lm)
```
№4
Оцениваем линейную модель. После анализа мультиколлинеарности осталось 4 регрессора (ISI, DMC, temp, RH). Ещё раз удостоверимся, что при таком наборе мультиколлинеарности почти нет. CN, который стал достаточно малым (33.5). VIF также говорят, что можно считать, что нет значительной мультиколлинеарности. И из-за этого, к слову, особой разницы в коэффициентах между LASSO и lm нет.

Интерпретация коэффициентов(значим коэффициент только при ISI(p-value=0.07,т.е. на 10% уровне значимости считаем, что не равен 0), для остальных особого смысла в интерпретации нет, но возможно с другими se будет другая значимость, потому на всякий и это проинтерпретируем) :

DMC=0.049: как и ожидалось, с ростом индекса влажности потенциально возгораемых слоёв увеличивается площадь сгораемой территории, потому что топливо проще разгорается, когда сухое. Если точно, то при увеличении индекса на 1 площадь увеличивается на 0.049 га при прочих равных.

ISI=-1.112: интерпретация - с ростом индекса распространения пожара на 1 площадь пожара уменьшается на 1.1 га при прочих равных. Влияние индекса оказалось контринтуитивным и не совпадает с ожиданиями, однако оно значимое(на 10% уровне). Надо попытаться объяснить:

1) с поведенческой точки зрения, возможно более низкие при прочих равных значений индекса кажутся пожарным не такими страшными, и потому на борьбу с пожарами бросается недостаточное количество людей, а потому захватывается пожаром большая площадь, чем даже при высоком значении индекса, на которое среагировали должным образом. Для этой гипотезы есть у меня даже косвенное доказательство. Согласно сайту (https://www.malagaweather.com/fwi-txt.htm) значения 10-16 считаются для этого индекса высокими, 16+ - экстремальным. И, если посмотреть на график зависимости только area от ISI (вполне законно, т.к. остальные переменные всё равно не значимы), то видно, что самые большие площади были сожжены при значениях ISI ДО 10, но близких к 10. То есть возможно действительно имела место недооценка возможного распространения. Однако, чтобы точно это замерить, нужно смотреть количество пожарных и прочее..
2) Если смотреть с точки зрения методологии, то индекс считается на основе данных индекса FFMC и измерений скорости ветра. Лаг его расчёта в районе дня, т.е. в нём информация за день. В таком случае проблема может быть в том, что для определённых дней погода сильно менялась и занижала изначально высокое значение индекса. И вообще для такого индекса, имеющего лаг в измерении, лучше брать значение за предыдущий день. Тогда возможно зависимость была бы всё же положительной.

temp=0.384: с ростом температуры на градус цельсия площадь увеличивается на 0.38 га при прочих равных. Вполне соответствует интуиции и ожиданиям о знаке(+).

RH=-0.073: с ростом относительной влажности воздуха на 1% площадь выгоревшая уменьшается на 0.073 га при прочих равных. Тоже соответствует ожиланиям и логике.

Тест на общую незначимость коэффициентов модели даёт F-статистику 1.355 с p-value 0.25, т.е. даже на 10% уровне значимости мы принимаем гипотезу о том, что все коэффициенты равны нулю и модель незначима. Как уже отмечалось, действительно прогнозирование просто константой даёт не сильно большие значения среднего квадратов остатков, но таковы уж данные. 

Тест Шапиро-Уилка отвергает гипотезу о нормальности остатков(p-value=10^-16, т.е. на любом вменяемом уровне значимости), поэтому скорее всего нарушаются предположения теоремы Гаусса-Маркова о нормальности случайных ошибок, а потому статистики и доверительные интервалы не корректно считать так, как мы это сделали.
```{r}
set.seed(14)
#Проверим ещё раз на мультиколлинеарность итоговую модель:
x5=as.matrix(data[,c(4,6:8)]) #матрица регрессоров (ISI,DMC,RH,temp)
kappa(x5)


#Сама модель
fit <- lm(area~DMC+ISI+temp+RH, data)
summary(fit)
vif(fit)

#LASSO для сравнения
lasso5 <- cv.glmnet(x = x5, y=data$area, type.measure = "mse",family = 'gaussian', alpha=1) #оцениваем кросс-валидацией лучшую лямбду
lambda5 <- lasso5$lambda.min #запоминаем её
coef5 <- lasso5$glmnet.fit$beta[,lasso5$glmnet.fit$lambda==lambda5] #записываем коэффициенты (без константы)
coef5
mean((data$area-predict(lasso5,s=lambda5,newx=x5))^2) #средний квадрат отклонений (lasso)
mean((fit$residuals)^2) 

#Для интерпретации

stargazer(fit,title="Зависимость площади пожара от природных факторов", type="text", 
                                        column.labels=c("Итоговая модель"), 
                                        df=FALSE, digits=3)
#График зависимости переменных для интерпретации
ggplot(data=data, aes(x=ISI, y=area)) +
 geom_point() +
 labs(title="Distribution of burned area by ISI",y="Burned area in ha")

#Нормальность остатков
shapiro.test(fit$residuals)
```
N4. Bootstrap. Реализация пакета boot и собственная функция. Дальше с помощью пакета смотрим доверительные интервалы эмпирические. Как видно, 95% интервалы (где мы просто отрезали по 250 наблюдений с каждой стороны), всё также говорят о незначимости всех переменных, кроме ISI, т.к. пересекают 0. Это видно и на самодельных интервалах и на пакетной реализации, где ещё дополнительная коррекция делается. На 10% значимой становится ещё и константа.
```{r}
set.seed(14)
#Пакетная реализация
#Для сбора статистики
bs <- function(formula, data, indices) {
  d <- data[indices,] 
  fit <- lm(formula, data=d)
  return(coef(fit)) 
} 
results <- boot(data=data, statistic=bs, 
   R=10000, formula=area~ DMC + ISI + temp + RH)

#Самодельная функция для линейной регрессии (на вход данные, вектор переменных, число выборок и формула. Возвращает dataframe с коэффициентами)
custom_bs <- function(data,variables,n,formula) {
  beta <- data.frame()
for (i in 1:n) {
  index<- sample(1:nrow(data),nrow(data),replace = TRUE )
  sample <- data[index,variables]
  model <- lm(formula=formula, sample)
  beta <- rbind(beta,data.frame(t(model$coefficients)))
}
  return(beta)
}
custom_results <- custom_bs(data,c(4,6:8,10),10000,area~ DMC + ISI + temp + RH)

#Доверительные интервалы из пакета (95%), скорректированные (BCa)
boot.ci(results, type="bca", index=1) #константа
boot.ci(results, type="bca", index=2) #DMC 
boot.ci(results, type="bca", index=3) #ISI
boot.ci(results, type="bca", index=4) #temp
boot.ci(results, type="bca", index=5) #RH

#Обычные квантильные доверительные интервалы по данным из самодельной функции n-ый
custom_ci <- function(data,n){  #на вход переменная, по которой нужен интервал и уровень значимости в долях.
  quantile(data,c(n,1-n))
}
n=0.01 #делаем 1% интервал
custom_ci(custom_results$X.Intercept.,n)
custom_ci(custom_results$DMC,n)
custom_ci(custom_results$ISI,n)
custom_ci(custom_results$temp,n)
custom_ci(custom_results$RH,n)


```


№5. Прогноз.
```{r}
nw <- data.frame(DMC = median(data$DMC),ISI = median(data$ISI), temp= median(data$temp), RH = median(data$RH))
head(nw)
predict(fit, newdata = nw, interval = 'prediction')
predict(fit, newdata = nw, interval = 'confidence')
```
№6.
Гетероскедастичность - это ситуация, когда дисперсия случайных ошибок - не константа. Обычно данные зашумлены, поэтому её можно ожидать почти всегда. Но по какой переменной? Да по каждой, если задуматься:

1) temp, т.к. скорее всего на низких температурах у нас пожары в среднем одинаково маленькую площадь затрагивают, небольшой разброс, тогда как при высокой температуре многие другие факторы могут кардинально изменить влияние (тот же ветер), а потому разброс значений площади с ростом температуры будет расти, а следовательно и ошибки тоже.
2) RH, т.к. при высокой влажности воздуха возгорания менее вероятны и наверное будут быстрее затухать, а вот при низкой влажности и высокой особенно температуре и вероятность возгорания увеличивается и скорость распространения (т.к. по сухой, а не влажной от испарения траве проще распространяться огню). Так что тут ожидаем нисходяющую дисперсию ошибок.
3) DMC - при низких значениях, как уже уточнялось, этот индекс показывает говорит о том, что горючие материалы влажные, т.е. распространение наверное будет в рамках небольшой области, в то же время большие значения говорят о сухости, т.е. у вас почти хворост, готовый от каждой искры загореться, и тогда уже другие факторы вполне могут вмешиваться и увеличивать волатильности площади пожара. Т.е. ожидаем положительной зависимости разброса случайных ошибок от DMC.
4) ISI- наконец, как уже говорилось ранее, у этого индекса взаимосвязь с area значимая и есть подозрение на эффект от человеческого фактора при значениях в районе 10. То есть опять же для этого индекса распространения можно ожидать в середине (10 находится где-то посередение в доступных данных) всплеск волатильности ошибок.

№7.
И тесты, и анализ остатков в общем-то показывает, что гетероскедастичность-таки можно найти по любой переменной. В целом идейные предположения подтвердились: графически для temp и DMC остатки сильнее колеблются при высоких значениях, для RH - при низких, для ISI -посередине.

Формальный тест Гольдфельда-Квандта в зависимости от того, какую часть выборки в середине при разбиени удаляем, даёт разные результаты для temp и RH - или есть или нет, но вот для индексов совершенно точно при любом значении изымаемой из центра выборки на 1% уровне значимости отвергается гипотеза для отсутствия гетероскедастичности, так что мы можем утверждать, что она тут есть.

Итог: гетероскедастичность есть в модели.
```{r}
#Графики
ggplot(data=data, aes(x=ISI, y=fit$residuals)) +
 geom_point() +
 labs(title="Interconnection between residuals and fire spread index ISI",y="Residuals of fitted model in ha")
ggplot(data=data, aes(x=temp, y=fit$residuals)) +
 geom_point() +
 labs(title="Interconnection between residuals and air temperature",y="Residuals of fitted model in ha", x="Temperature in Celsius degrees")
ggplot(data=data, aes(x=RH, y=fit$residuals)) +
 geom_point() +
 labs(title="Interconnection between residuals and relative humidity",y="Residuals of fitted model in ha",x="elative humidity в %")
ggplot(data=data, aes(x=DMC, y=fit$residuals)) +
 geom_point() +
 labs(title="Interconnection between residuals and DMC",y="Residuals of fitted model in ha")


#Гольдфельд-Квандт 

m=0.1#Какую часть выборки вырезаем из центра
#Для temp
gqtest(fit, fraction=m, alternative = c("greater"),
  order.by = data$temp)
gqtest(fit, fraction=m, alternative = c("less"),
  order.by = data$temp)
gqtest(fit, fraction=m, alternative = c("two.sided"),
  order.by = data$temp)
#Для RH
gqtest(fit, fraction=m, alternative = c("greater"),
  order.by = data$RH)
gqtest(fit, fraction=m, alternative = c("less"),
  order.by = data$RH)
gqtest(fit, fraction=m, alternative = c("two.sided"),
  order.by = data$RH)
#Для ISI
gqtest(fit, fraction=m, alternative = c("greater"),
  order.by = data$ISI)
gqtest(fit, fraction=m, alternative = c("less"),
  order.by = data$ISI)
gqtest(fit, fraction=m, alternative = c("two.sided"),
  order.by = data$ISI)
#Для  DMC
gqtest(fit, fraction=m, alternative = c("greater"),
  order.by = data$DMC)
gqtest(fit, fraction=m, alternative = c("less"),
  order.by = data$DMC)
gqtest(fit, fraction=m, alternative = c("two.sided"),
  order.by = data$DMC)


```
№8
Взвешенный МНК (частный случай ОМНК) оцениваем, исходя из предположения о диагональности ковариационной матрицы случайных ошибок и не фиксированной дисперсии каждой ошибки. Чтобы оценить то, что стоит на диагонали, надо ввести какие-то предпосылки относительно того, от каких параметров наши ошибки/остатки зависят. По результатам теста Гольдфельда Квандта из пункта 7 можно предположить, что зависят они от ISI и DMC (можно было бы не париться и просто взять регрессию e~y, но для интереса сделаем так). Тогда посчитаем регрессию остатков на них, возьмём оценённые значения остатков и используем их квадраты как оценочные значения дисперсий, которые стоят на диагонали матрицы ковариации. А дальше дело техники: просто подставим их в матричное уравнение для коэффициентов модели.

Ниже приведено сравнение моделей со стандартными ошибками и значимостью. В итоге разница между моделями значительна (между исходной и Взвешенный МНК1): во-первых, стала значима переменная температуры, которая сменила знак, во-вторых, значима стала константа. Также важно отметить, что теперь гипотеза о значимости уравнения не отвергается, как это было с первоначальной моделью.

Метаморфозы с температурой, которая теперь имеет контринтутивное влияние(отрицательное), могут быть свидетельством того, что предпосылка об устройстве матрицы ковариации не верна (на это же намекает слишком высокий R^2). На всякий случай была оценена ещё и модель взвешенного МНК 2 (в таблице последняя), сделанная из предположения, что остатки зависят от оценённых в изначальной модели y: e~y. Коэффициенты этой модели поддерживают положительное влияние temp на площадь пожара, при этом переменная значимая. Также (на уровне значимости 10%) отвергается гипотеза о том, что всё уравнение целиком не значимо.

На основе этого анализа можно сделать выводы, что много переменных не учтено (раз константа значимая), а также что стоит более реалистичные предположения наложить на матрицу ковариации случайных ошибок.
```{r}
#Оцениваем связь ошибок и переменных? и строим на их основе диагональную матрицу ковариации W:
W <- diag(abs(lm(fit$residuals^2~data$DMC+data$ISI)$fitted.values))#возьмём оценки по модулю, иначе будет отрицательная определённность матрицы.
datfeel <- data
datfeel$intercept <- rep(1,266)
X <- as.matrix(datfeel[,c(11,4,6:8)]) #Матрица регрессоров с добавленной константой
Y <- as.matrix(data[,10]) #зависимая переменная
beta <- solve(t(X)%*%solve(W)%*%X)%*%t(X)%*%solve(W)%*%Y #Оценка взвешенного МНК

#Пакетная реализация
weights <- 1/abs(lm(fit$residuals^2~data$DMC+data$ISI)$fitted.values)
WOLS <- lm(area~DMC+ISI+temp+RH, data, weights=weights )
summary(WOLS) #Если сравнить коэффициенты c оцененными самостоятельно, то они будут одинаковыми- истинная магия эконометрики

#Другое предположение о связи e с переменными: e~y
weights1 <- 1/abs(lm(fit$residuals^2~fit$fitted.values)$fitted.values)
WOLS1 <- lm(area~DMC+ISI+temp+RH, data, weights=weights1 )
summary(WOLS1)
#Сравнение
stargazer(fit,WOLS,WOLS1,title = "Сравнение обычного МНК и взвешенного",type="text", 
                                        column.labels=c("МНК", "Взвешенный МНК 1", "Взвешенный МНК 2"), 
                                        df=FALSE, digits=3)

```
№9. 
HC0.
Основная идея ошибок Уайта в том, что мы предполагаем ковариационную матрицу диагональной со значениями дисперсий ошибок равных квадратам остатков модели (то есть не переоцениваем эти остатки с дополнительными предположениями, а в лоб принимаем их дисперсиями). А дальше с такой оценкой считаем матрицу ковариации коэффициентов, как если бы мы делали это через ОМНК. Таким образом коэффициенты в модели не меняются, но их стандартные ошибки строятся в предположении о другом виде ковариационной матрицы случайных ошибок. 

HC3 отличаются только тем, что там предположение о матрице ковариации другое: через h_ij.

Ниже процедура оценки HC0 и HC3 и статистики. Видно, что значимости добавилось только коэффициенту при индексе ISI в сравнении с обычными МНК se.
```{r}
#HC0 самостоятельно для данной модели

W1 <- diag(fit$residuals^2) #ковариационная матрица в рамках предположений HC0
datfeel <- data
datfeel$intercept <- rep(1,266)
X <- as.matrix(datfeel[,c(11,4,6:8)]) #Матрица регрессоров с добавленной константой
Y <- as.matrix(data[,10]) #зависимая переменная
Var_beta <- solve(t(X)%*%X)%*%t(X)%*%W1%*%X%*%solve(t(X)%*%X) #ковариационная матрица коэффициентов(нам нужны корни диагональных элементов-дисперсий)
HC0 <- sqrt(diag(Var_beta)) #Итоговые стандартные ошибки

#HC0 из пакета
cse = function(reg) {
  rob = sqrt(diag(vcovHC(reg, type = "HC0")))
  return(rob)
}
cse(fit)

#Статистика для HC0
coeftest(fit, vcov = vcovHC(fit, type = "HC0"))

#HC3 из пакета
cse1 = function(reg) {
  rob = sqrt(diag(vcovHC(reg, type = "HC3")))
  return(rob)
}
#Представление модели в таблице с ошибками HC0 и HC3
stargazer(fit, fit,fit,   
          se=list(HC0,cse(fit),cse1(fit)), 
          title="Сравнение стандартных ошибок в разных формах", type="text", 
          column.labels=c("HC0 своё","HC0","HC3"), report = "vcstp*",
          df=FALSE, digits=3)
```

№9 
PCA. Строятся просто в пакете. Идейно мы смешиваем все переменные так, чтобы в итоговых получилась наибольшая вариации, при этом все они линейно-независимы. Так устраняется мультиколлинеарность. Чисто теоретически можно эти главные компоненты ко всем отброшенным из-за мультиколлинеарности переменным применить, но оставим так. Объясняемые первыми двумя компонентами доли дисперсии соответственно 0.5038 и 0.2638 (суммарно больше 3/4).

Модель по двум первым компонентам не сильно улучшила предсказания(R^2 всё также низок), и при этом уничтожила интерпретацию (так как эти взвешенные переменные содержательно мало что значат), к тому же коэффициенты перед векторами незнечимы.
```{r}
set.seed(14)
#выделяем главные компоненты
dfpca <- prcomp(data[c(4,6:8)], center = TRUE,scale. = TRUE)

#Записываем 1 и 2-ю компоненты
x1 <- dfpca$x[,1]
x2 <- dfpca$x[,2]
#Доли дисперсии через summary смотрим
summary(dfpca)

#модель
model <- lm(data$area ~ x1+x2)
summary(model)
stargazer(model,title = "Регрессия на главные компоненты",type="text", 
                                        column.labels=c("МНК"), 
                                        df=FALSE, digits=3)
```



